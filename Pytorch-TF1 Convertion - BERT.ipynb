{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e64fae",
   "metadata": {},
   "source": [
    "# Bert to Tensorflow 1 Convertion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce19462",
   "metadata": {},
   "source": [
    "## 1. Pytorch to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54dbc6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31bda30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'BertLarge'\n",
    "\n",
    "model = BertModel.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281a55a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(29794, 1024, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 1024)\n",
      "    (token_type_embeddings): Embedding(2, 1024)\n",
      "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-23): 24 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee2cbc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o tamanho de entrada (por exemplo, tamanho do token)\n",
    "# Aqui, '128' é um exemplo de tamanho de sequência. Você pode precisar ajustar isso conforme necessário\n",
    "\n",
    "input_ids = torch.randint(0, 2000, (1, 128)) # Exemplo de tensor de IDs de token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd6649b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especifique o caminho para salvar o modelo ONNX\n",
    "output_onnx_path = \"ONNX/BertLarge.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6be28bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo BERTimbau exportado para ONNX com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Exporte o modelo para o formato ONNX\n",
    "torch.onnx.export(model, input_ids, output_onnx_path, export_params=True, opset_version=11, \n",
    "                  do_constant_folding=True, input_names=['input_ids'], \n",
    "                  output_names=['output'], dynamic_axes={'input_ids' : {0 : 'batch_size'}, \n",
    "                  'output' : {0 : 'batch_size'}})\n",
    "\n",
    "print(\"Modelo BERTimbau exportado para ONNX com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42813a9",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0696b0b9",
   "metadata": {},
   "source": [
    "## 1.1 Teste de Inferência - Modelo ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c199a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47da3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o tokenizador\n",
    "tokenizer = BertTokenizer.from_pretrained(\"BertLarge\")\n",
    "\n",
    "# Carregar o modelo ONNX\n",
    "onnx_model_path = \"ONNX/BertLarge.onnx\"\n",
    "session = ort.InferenceSession(onnx_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83c9ef85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representação [CLS]: [-0.7848451   0.7218873  -0.8953569  ...  0.27494764 -0.384354\n",
      " -0.25554106]\n"
     ]
    }
   ],
   "source": [
    "# Preparar os dados de entrada\n",
    "text = \"I loved this book.\" \n",
    "inputs = tokenizer(text, return_tensors=\"pt\", max_length=128, truncation=True, padding=\"max_length\")\n",
    "input_ids = inputs[\"input_ids\"].numpy()\n",
    "\n",
    "# Realizar a inferência\n",
    "outputs = session.run(None, {'input_ids': input_ids})\n",
    "\n",
    "# Usar a representação do token [CLS] (primeiro token)\n",
    "cls_representation = outputs[0][0, 0, :]\n",
    "\n",
    "print(\"Representação [CLS]:\", cls_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a96c5f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe prevista: 456\n"
     ]
    }
   ],
   "source": [
    "# Preparar os dados de entrada\n",
    "text = \"I loved this book.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", max_length=128, truncation=True, padding=\"max_length\")\n",
    "input_ids = inputs[\"input_ids\"].numpy()\n",
    "\n",
    "# Realizar a inferência\n",
    "outputs = session.run(None, {\"input_ids\": input_ids})\n",
    "\n",
    "# Processar a saída\n",
    "output = outputs[0]\n",
    "\n",
    "# Função auxiliar softmax\n",
    "def softmax(x, axis=None):\n",
    "    e_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=axis, keepdims=True)\n",
    "\n",
    "# Softmax sobre logits e predição\n",
    "probabilities = softmax(output[0], axis=1)\n",
    "predicted_class = np.argmax(probabilities, axis=1)[0]\n",
    "\n",
    "print(\"Classe prevista:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5b490e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato da saída: (1, 128, 1024)\n"
     ]
    }
   ],
   "source": [
    "output = outputs[0]\n",
    "print(\"Formato da saída:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194213e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f11b1",
   "metadata": {},
   "source": [
    "## 2. ONNX to Tensorflow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a3af54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Carregar o modelo ONNX\n",
    "onnx_model = onnx.load(\"ONNX/BertLarge.onnx\")\n",
    "\n",
    "# Converter o modelo ONNX para TensorFlow 2.x\n",
    "tf_rep = prepare(onnx_model)\n",
    "\n",
    "# Salvar o modelo TensorFlow 2.x\n",
    "tf_rep.export_graph(\"BertLarge_tf2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539190d4",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c24467",
   "metadata": {},
   "source": [
    "## Teste do modelo Tensorflow convertido do ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75c5f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "model_path = 'BertLarge'\n",
    "# Carregar o tokenizer correspondente ao seu modelo BERT\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Texto de exemplo para inferência\n",
    "texto_exemplo = \"Hello, how are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db534175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizar o texto\n",
    "inputs = tokenizer(texto_exemplo, return_tensors=\"tf\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "# Extrair input_ids e converter para int64\n",
    "input_ids = tf.cast(inputs[\"input_ids\"], tf.int64)\n",
    "\n",
    "# Carregar o modelo TensorFlow\n",
    "model = tf.saved_model.load(\"BertLarge_tf2\")\n",
    "\n",
    "# Preparar os dados de entrada como um dicionário\n",
    "input_data = {'input_ids': input_ids}\n",
    "\n",
    "# Realizar inferência\n",
    "output = model.signatures['serving_default'](**input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79557a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature: serving_default\n",
      "Inputs: [<tf.Tensor 'input_ids:0' shape=(None, 128) dtype=int64>, <tf.Tensor 'unknown:0' shape=(29794, 1024) dtype=float32>, <tf.Tensor 'unknown_0:0' shape=(2, 1024) dtype=float32>, <tf.Tensor 'unknown_1:0' shape=(512, 1024) dtype=float32>, <tf.Tensor 'unknown_2:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_3:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_4:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_5:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_6:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_7:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_8:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_9:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_10:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_11:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_12:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_13:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_14:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_15:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_16:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_17:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_18:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_19:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_20:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_21:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_22:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_23:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_24:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_25:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_26:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_27:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_28:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_29:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_30:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_31:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_32:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_33:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_34:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_35:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_36:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_37:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_38:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_39:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_40:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_41:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_42:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_43:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_44:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_45:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_46:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_47:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_48:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_49:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_50:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_51:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_52:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_53:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_54:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_55:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_56:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_57:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_58:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_59:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_60:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_61:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_62:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_63:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_64:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_65:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_66:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_67:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_68:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_69:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_70:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_71:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_72:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_73:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_74:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_75:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_76:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_77:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_78:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_79:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_80:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_81:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_82:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_83:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_84:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_85:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_86:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_87:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_88:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_89:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_90:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_91:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_92:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_93:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_94:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_95:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_96:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_97:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_98:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_99:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_100:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_101:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_102:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_103:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_104:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_105:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_106:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_107:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_108:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_109:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_110:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_111:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_112:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_113:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_114:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_115:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_116:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_117:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_118:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_119:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_120:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_121:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_122:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_123:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_124:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_125:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_126:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_127:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_128:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_129:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_130:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_131:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_132:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_133:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_134:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_135:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_136:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_137:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_138:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_139:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_140:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_141:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_142:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_143:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_144:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_145:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_146:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_147:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_148:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_149:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_150:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_151:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_152:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_153:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_154:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_155:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_156:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_157:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_158:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_159:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_160:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_161:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_162:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_163:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_164:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_165:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_166:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_167:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_168:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_169:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_170:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_171:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_172:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_173:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_174:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_175:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_176:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_177:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_178:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_179:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_180:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_181:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_182:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_183:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_184:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_185:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_186:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_187:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_188:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_189:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_190:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_191:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_192:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_193:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_194:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_195:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_196:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_197:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_198:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_199:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_200:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_201:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_202:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_203:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_204:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_205:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_206:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_207:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_208:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_209:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_210:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_211:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_212:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_213:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_214:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_215:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_216:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_217:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_218:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_219:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_220:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_221:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_222:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_223:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_224:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_225:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_226:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_227:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_228:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_229:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_230:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_231:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_232:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_233:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_234:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_235:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_236:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_237:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_238:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_239:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_240:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_241:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_242:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_243:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_244:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_245:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_246:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_247:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_248:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_249:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_250:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_251:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_252:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_253:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_254:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_255:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_256:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_257:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_258:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_259:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_260:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_261:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_262:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_263:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_264:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_265:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_266:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_267:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_268:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_269:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_270:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_271:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_272:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_273:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_274:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_275:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_276:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_277:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_278:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_279:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_280:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_281:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_282:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_283:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_284:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_285:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_286:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_287:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_288:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_289:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_290:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_291:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_292:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_293:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_294:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_295:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_296:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_297:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_298:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_299:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_300:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_301:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_302:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_303:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_304:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_305:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_306:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_307:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_308:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_309:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_310:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_311:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_312:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_313:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_314:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_315:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_316:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_317:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_318:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_319:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_320:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_321:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_322:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_323:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_324:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_325:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_326:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_327:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_328:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_329:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_330:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_331:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_332:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_333:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_334:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_335:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_336:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_337:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_338:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_339:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_340:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_341:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_342:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_343:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_344:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_345:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_346:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_347:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_348:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_349:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_350:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_351:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_352:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_353:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_354:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_355:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_356:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_357:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_358:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_359:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_360:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_361:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_362:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_363:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_364:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_365:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_366:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_367:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_368:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_369:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_370:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_371:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_372:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_373:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_374:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_375:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_376:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_377:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_378:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_379:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_380:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_381:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_382:0' shape=(1024, 4096) dtype=float32>, <tf.Tensor 'unknown_383:0' shape=(4096,) dtype=float32>, <tf.Tensor 'unknown_384:0' shape=(4096, 1024) dtype=float32>, <tf.Tensor 'unknown_385:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_386:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_387:0' shape=(1024,) dtype=float32>, <tf.Tensor 'unknown_388:0' shape=(1024, 1024) dtype=float32>, <tf.Tensor 'unknown_389:0' shape=(1024,) dtype=float32>]\n",
      "Outputs: [<tf.Tensor 'Identity:0' shape=(None, 1024) dtype=float32>, <tf.Tensor 'Identity_1:0' shape=(None, 128, 1024) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# Verificar a assinatura do modelo\n",
    "for f in model.signatures:\n",
    "    print('Signature:', f)\n",
    "    print('Inputs:', model.signatures[f].inputs)\n",
    "    print('Outputs:', model.signatures[f].outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fa2059",
   "metadata": {},
   "source": [
    "Saídas do Modelo: Last Hidden State e Pooled Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7bff4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': <tf.Tensor: shape=(1, 512, 1024), dtype=float32, numpy=\n",
      "array([[[-1.405883  , -0.5071652 , -0.19600448, ..., -0.14475238,\n",
      "          0.7742399 ,  0.60961187],\n",
      "        [ 0.0534275 ,  1.2149448 ,  0.14572959, ...,  0.11436579,\n",
      "         -0.3873235 ,  0.46369135],\n",
      "        [-0.25096303,  0.94107556,  0.12726949, ..., -0.41458088,\n",
      "         -0.02168075,  0.05212868],\n",
      "        ...,\n",
      "        [-1.4619552 , -0.5172862 , -0.20580854, ..., -0.15467204,\n",
      "          0.78893995,  0.5971466 ],\n",
      "        [-1.4630004 , -0.517497  , -0.20602077, ..., -0.15482968,\n",
      "          0.7891975 ,  0.59694535],\n",
      "        [-1.4503597 , -0.51505363, -0.20361568, ..., -0.1528167 ,\n",
      "          0.7860867 ,  0.5994793 ]]], dtype=float32)>, '3024': <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
      "array([[ 0.8851668 ,  0.6478177 ,  0.73255414, ..., -0.22627208,\n",
      "        -0.96188384, -0.37408417]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "# Saídas do Modelo: Last Hidden State e Pooled Output\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6032de8",
   "metadata": {},
   "source": [
    "Last Hidden State (output[0]): Representa as características (ou embeddings) de cada token na frase. Este é um tensor de forma (batch_size, sequence_length, hidden_size), que no caso é (1, 512, 1024). Cada token da sequência de entrada é representado por um vetor de 1024 dimensões.\n",
    "\n",
    "Pooled Output (output[1]): É uma representação agregada da entrada inteira, normalmente usada em tarefas de classificação. Este é um tensor de forma (batch_size, hidden_size), que no caso é (1, 1024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffd9925d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.405883  , -0.5071652 , -0.19600448, ..., -0.14475238,\n",
       "          0.7742399 ,  0.60961187],\n",
       "        [ 0.0534275 ,  1.2149448 ,  0.14572959, ...,  0.11436579,\n",
       "         -0.3873235 ,  0.46369135],\n",
       "        [-0.25096303,  0.94107556,  0.12726949, ..., -0.41458088,\n",
       "         -0.02168075,  0.05212868],\n",
       "        ...,\n",
       "        [-1.4619552 , -0.5172862 , -0.20580854, ..., -0.15467204,\n",
       "          0.78893995,  0.5971466 ],\n",
       "        [-1.4630004 , -0.517497  , -0.20602077, ..., -0.15482968,\n",
       "          0.7891975 ,  0.59694535],\n",
       "        [-1.4503597 , -0.51505363, -0.20361568, ..., -0.1528167 ,\n",
       "          0.7860867 ,  0.5994793 ]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando Last Hidden State para extração de características\n",
    "last_hidden_state = output['output'].numpy()\n",
    "last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bda6f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.405883  , -0.5071652 , -0.19600448, ..., -0.14475238,\n",
       "        0.7742399 ,  0.60961187], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo: Obtendo o embedding do primeiro token (geralmente [CLS] em BERT)\n",
    "first_token_embedding = last_hidden_state[0][0]\n",
    "first_token_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96211560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8851668 ,  0.6478177 ,  0.73255414, ..., -0.22627208,\n",
       "        -0.96188384, -0.37408417]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "<hr># Acessar o Pooled Output\n",
    "pooled_output = output['3024'].numpy()\n",
    "pooled_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437a751d",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a7751",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00389635",
   "metadata": {},
   "source": [
    "# Conversão do BertLarge: Pytorch >> TF 2.x .h5 e Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47ebe4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig, TFBertModel\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "# Caminho para o seu modelo PyTorch .bin\n",
    "path_to_pytorch_model = 'BertLarge'\n",
    "\n",
    "# Carrega o modelo PyTorch\n",
    "config = BertConfig.from_pretrained(path_to_pytorch_model)\n",
    "pytorch_model = BertModel.from_pretrained(path_to_pytorch_model, config=config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c405b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Converte o modelo PyTorch para TensorFlow\n",
    "tensorflow_model = TFBertModel.from_pretrained(path_to_pytorch_model, config=config, from_pt=True)\n",
    "\n",
    "# Salva o modelo TensorFlow como um checkpoint .h5 e o seu config.json\n",
    "tensorflow_model.save_pretrained('Modelo_Tensorflow2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5df05210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Checkpoints_Tensorflow\\\\ckpt-1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cria um objeto Checkpoint do TensorFlow\n",
    "ckpt = tf.train.Checkpoint(model=tensorflow_model)\n",
    "\n",
    "# Salva o modelo no formato .ckpt\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, 'Checkpoints_Tensorflow2', max_to_keep=1)\n",
    "ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8187a821",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7180e1",
   "metadata": {},
   "source": [
    "# Carregamento do modelo TF 2.x em formato .h5 e os Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import BertConfig\n",
    "\n",
    "\n",
    "# Carrega a configuração do modelo\n",
    "config = BertConfig.from_json_file('Modelo_Tensorflow2/config.json')\n",
    "\n",
    "# Inicialize o modelo com esta configuração\n",
    "# Carrega o modelo\n",
    "model = TFBertForSequenceClassification.from_pretrained('Modelo_Tensorflow2/tf_model.h5', config=config)\n",
    "\n",
    "# Carrega o Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('BertLarge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0b42e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.InitializationOnlyStatus at 0x1a711993700>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crie um objeto tf.train.Checkpoint que gerenciará os checkpoints\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "\n",
    "# Caminho para o diretório do checkpoint\n",
    "checkpoint_path = \"Checkpoints_Tensorflow2/ckpt\"\n",
    "\n",
    "# Carrega os pesos do checkpoint\n",
    "ckpt.restore(tf.train.latest_checkpoint(checkpoint_path)).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ba7dd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.checkpoint.checkpoint.Checkpoint object at 0x000001A711AEC070>\n"
     ]
    }
   ],
   "source": [
    "print(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51cff2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe predita: 0\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de texto para fazer a inferência\n",
    "input_text = \"Exemplo de texto para teste.\"\n",
    "\n",
    "# Tokeniza o texto\n",
    "inputs = tokenizer(input_text, return_tensors=\"tf\", truncation=True, max_length=512)\n",
    "\n",
    "# Realiza a inferência\n",
    "outputs = model(inputs)\n",
    "\n",
    "# As saídas são logits, aplicar softmax para obter probabilidades\n",
    "predictions = tf.nn.softmax(outputs.logits, axis=-1)\n",
    "\n",
    "# Obter a classe com a maior probabilidade\n",
    "predicted_class_idx = tf.argmax(predictions, axis=-1).numpy()[0]\n",
    "\n",
    "print(\"Classe predita:\", predicted_class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7602a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.5430834 , 0.45691657]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2247eaa5",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a94f77",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374c64c",
   "metadata": {},
   "source": [
    "# Recriar o modelo TensorFlow 2.x em Tensorflow 1.x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924ebde",
   "metadata": {},
   "source": [
    "## 1. Salvar os Pesos do Modelo TensorFlow 2.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5947a414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n",
      "classifier\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "weights = []\n",
    "for layer in model.layers:\n",
    "\n",
    "    w = layer.get_weights()\n",
    "    if len(w)>0:\n",
    "      print(layer.name)\n",
    "      weights.append(w)\n",
    "\n",
    "\n",
    "with open('Bert-large_weights.pkl', 'wb') as f:\n",
    "  pickle.dump(weights, f)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77dd431",
   "metadata": {},
   "source": [
    "## 2. Recriar o Modelo e Carregar os Pesos no TensorFlow 1.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ad36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda activate tf1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir o Jupyter Notebook a partir do env de TF 1.15.5\n",
    "\n",
    "# python -m ipykernel install --user --name=tf1.15 --display-name=\"Python 3.6.13 (tf1.15)\"\n",
    "\n",
    "# jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3fc1ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabf217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from transformers import BertConfig, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42146736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "942fa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os pesos do arquivo pickle\n",
    "with open('Bert-large_weights.pkl', 'rb') as f:\n",
    "    weights = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4acdd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No env com TensorFlow 1.x instalado\n",
    "# Recriando a arquitetura do modelo BERT Large no TensorFlow 1.x\n",
    "\n",
    "# Caminho para a pasta do BERT\n",
    "bert_dir = \"bert_cased_L-24_H-1024_A-16\"\n",
    "\n",
    "# Carregar a configuração do BERT\n",
    "bert_config = modeling.BertConfig.from_json_file(os.path.join(bert_dir, \"bert_config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6b840d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reiniciar o grafo TensorFlow para evitar conflitos de variáveis\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856991db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.training import saver as saver_lib\n",
    "from bert import modeling\n",
    "\n",
    "# Supondo que 'bert_config' e 'weights' são carregados de acordo com suas necessidades\n",
    "\n",
    "# Criar a arquitetura do modelo BERT\n",
    "input_ids = tf.placeholder(tf.int32, [None, None])\n",
    "input_mask = tf.placeholder(tf.int32, [None, None])\n",
    "token_type_ids = tf.placeholder(tf.int32, [None, None])\n",
    "\n",
    "model = modeling.BertModel(\n",
    "    config=bert_config,\n",
    "    is_training=False,\n",
    "    input_ids=input_ids,\n",
    "    input_mask=input_mask,\n",
    "    token_type_ids=token_type_ids\n",
    ")\n",
    "\n",
    "# Inicialize uma sessão TensorFlow\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Obter todas as variáveis treináveis do modelo\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "# Mapear e carregar os pesos\n",
    "for var, layer_weights in zip(tvars, weights):\n",
    "    # Verificar se o peso é uma lista com dois elementos (pesos e vieses) ou um único tensor de pesos\n",
    "    if isinstance(layer_weights, list):\n",
    "        # Atribuir pesos e vieses\n",
    "        if len(layer_weights) == 2:\n",
    "            # Ajustar a forma dos pesos, se necessário\n",
    "            if var.shape.as_list() == [i for i in reversed(layer_weights[0].shape)]:\n",
    "                sess.run(var.assign(tf.transpose(layer_weights[0])))\n",
    "            else:\n",
    "                sess.run(var.assign(layer_weights[0]))\n",
    "        elif len(layer_weights) == 1:\n",
    "            # Atribuir apenas os pesos\n",
    "            # Ajustar a forma dos pesos, se necessário\n",
    "            if var.shape.as_list() == [i for i in reversed(layer_weights[0].shape)]:\n",
    "                sess.run(var.assign(tf.transpose(layer_weights[0])))\n",
    "            else:\n",
    "                sess.run(var.assign(layer_weights[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8438b946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert/embeddings/word_embeddings:0 (29794, 1024)\n",
      "bert/embeddings/token_type_embeddings:0 (2, 1024)\n",
      "bert/embeddings/position_embeddings:0 (512, 1024)\n",
      "bert/embeddings/LayerNorm/beta:0 (1024,)\n",
      "bert/embeddings/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_0/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_0/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_0/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_0/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_0/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_0/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_0/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_0/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_0/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_0/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_0/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_0/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_0/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_0/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_1/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_1/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_1/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_1/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_1/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_1/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_1/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_1/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_1/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_1/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_1/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_1/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_1/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_1/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_2/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_2/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_2/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_2/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_2/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_2/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_2/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_2/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_2/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_2/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_2/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_2/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_2/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_2/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_3/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_3/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_3/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_3/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_3/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_3/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_3/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_3/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_3/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_3/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_3/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_3/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_3/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_3/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_4/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_4/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_4/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_4/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_4/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_4/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_4/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_4/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_4/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_4/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_4/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_4/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_4/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_4/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_5/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_5/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_5/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_5/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_5/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_5/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_5/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_5/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_5/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_5/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_5/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_5/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_5/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_5/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_6/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_6/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_6/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_6/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_6/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_6/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_6/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_6/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_6/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_6/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_6/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_6/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_6/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_6/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_7/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_7/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_7/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_7/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_7/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_7/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_7/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_7/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_7/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_7/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_7/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_7/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_7/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_7/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_8/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_8/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_8/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_8/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_8/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_8/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_8/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_8/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_8/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_8/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_8/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_8/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_8/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_8/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_9/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_9/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_9/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_9/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_9/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_9/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_9/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_9/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_9/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_9/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_9/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_9/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_9/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_9/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_10/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_10/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_10/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_10/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_10/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_10/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_10/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_10/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_10/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_10/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_10/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_10/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_10/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_10/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_11/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_11/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_11/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_11/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_11/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_11/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_11/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_11/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_11/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_11/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_11/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_11/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_11/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_11/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_12/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_12/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_12/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_12/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_12/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_12/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_12/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_12/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_12/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_12/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_12/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_12/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_12/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_12/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_12/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_12/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_13/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_13/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_13/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_13/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_13/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_13/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_13/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_13/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_13/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_13/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_13/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_13/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_13/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_13/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_13/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_13/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_14/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_14/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_14/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_14/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_14/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_14/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_14/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_14/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_14/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_14/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_14/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_14/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_14/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_14/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_14/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_14/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_15/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_15/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_15/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_15/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_15/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_15/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_15/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_15/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_15/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_15/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_15/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_15/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_15/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_15/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_15/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_15/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_16/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_16/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_16/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_16/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_16/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_16/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_16/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_16/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_16/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_16/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_16/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_16/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_16/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_16/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_16/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_16/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_17/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_17/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_17/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_17/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_17/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_17/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_17/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_17/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_17/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_17/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_17/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_17/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_17/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_17/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_17/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_17/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_18/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_18/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_18/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_18/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_18/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_18/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_18/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_18/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_18/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_18/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_18/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_18/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_18/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_18/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_18/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_18/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_19/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_19/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_19/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_19/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_19/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_19/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_19/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_19/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_19/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_19/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_19/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_19/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_19/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_19/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_19/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_19/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_20/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_20/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_20/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_20/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_20/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_20/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_20/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_20/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_20/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_20/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_20/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_20/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_20/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_20/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_20/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_20/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_21/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_21/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_21/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_21/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_21/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_21/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_21/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_21/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_21/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_21/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_21/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_21/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_21/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_21/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_21/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_21/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_22/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_22/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_22/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_22/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_22/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_22/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_22/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_22/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_22/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_22/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_22/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_22/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_22/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_22/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_22/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_22/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_23/attention/self/query/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_23/attention/self/query/bias:0 (1024,)\n",
      "bert/encoder/layer_23/attention/self/key/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_23/attention/self/key/bias:0 (1024,)\n",
      "bert/encoder/layer_23/attention/self/value/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_23/attention/self/value/bias:0 (1024,)\n",
      "bert/encoder/layer_23/attention/output/dense/kernel:0 (1024, 1024)\n",
      "bert/encoder/layer_23/attention/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_23/attention/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_23/attention/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/encoder/layer_23/intermediate/dense/kernel:0 (1024, 4096)\n",
      "bert/encoder/layer_23/intermediate/dense/bias:0 (4096,)\n",
      "bert/encoder/layer_23/output/dense/kernel:0 (4096, 1024)\n",
      "bert/encoder/layer_23/output/dense/bias:0 (1024,)\n",
      "bert/encoder/layer_23/output/LayerNorm/beta:0 (1024,)\n",
      "bert/encoder/layer_23/output/LayerNorm/gamma:0 (1024,)\n",
      "bert/pooler/dense/kernel:0 (1024, 1024)\n",
      "bert/pooler/dense/bias:0 (1024,)\n"
     ]
    }
   ],
   "source": [
    "all_vars = tf.global_variables()\n",
    "for var in all_vars:\n",
    "    print(var.name, var.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33acb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'BertLarge_tf1_v4/model.ckpt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b218b9",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c3c9e2",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4033f092",
   "metadata": {},
   "source": [
    "### SUCESSO AO IMPRIMIR A SAÍDA DO MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7891035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Reiniciar o grafo TensorFlow para evitar conflitos de variáveis\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb2a9635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from bert import modeling, tokenization\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1bda73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No env com TensorFlow 1.x instalado\n",
    "# Recriando a arquitetura do modelo BERT Large no TensorFlow 1.x\n",
    "\n",
    "# Caminho para a pasta do BERT\n",
    "bert_dir = \"BertLarge_tf1_v4\"\n",
    "\n",
    "# Carregar a configuração do BERT\n",
    "bert_config = modeling.BertConfig.from_json_file(os.path.join(bert_dir, \"config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52944dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruir o grafo do modelo BERT\n",
    "input_ids = tf.placeholder(tf.int32, [None, None])\n",
    "input_mask = tf.placeholder(tf.int32, [None, None])\n",
    "token_type_ids = tf.placeholder(tf.int32, [None, None])\n",
    "\n",
    "model = modeling.BertModel(\n",
    "    config=bert_config,\n",
    "    is_training=False,\n",
    "    input_ids=input_ids,\n",
    "    input_mask=input_mask,\n",
    "    token_type_ids=token_type_ids\n",
    ")\n",
    "\n",
    "# Restaurar os pesos do modelo\n",
    "saver = tf.train.Saver()\n",
    "checkpoint_path = \"BertLarge_tf1_v4/model.ckpt\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restaurar os pesos\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    \n",
    "    \n",
    "    bert_output = sess.run(model.get_pooled_output(), feed_dict={\n",
    "        input_ids: input_ids_np,   # Chaves são os objetos tf.placeholder\n",
    "        input_mask: input_mask_np,\n",
    "        token_type_ids: segment_ids_np\n",
    "    })\n",
    "\n",
    "# Imprimir a saída do modelo\n",
    "print(\"BERT output:\", bert_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4649dd22",
   "metadata": {},
   "source": [
    "Reconstrução do Grafo do Modelo BERT: Primeiro, foi feita reconstrução da arquitetura do modelo BERT utilizando TensorFlow. Isso é feito definindo placeholders para input_ids, input_mask e token_type_ids, que são estruturas de dados padrão do TensorFlow usadas para alimentar dados para um modelo. Depois, criação de uma instância do modelo BERT (model) com esses placeholders como entrada.\n",
    "\n",
    "Restauração dos Pesos do Modelo: Uso de um objeto Saver do TensorFlow para carregar os pesos do modelo a partir de um checkpoint (checkpoint_path). Isso significa que o estado treinado do modelo BERT, incluindo todos os pesos e bias aprendidos durante o treinamento, foram carregados na sessão TensorFlow atual.\n",
    "\n",
    "Execução do Modelo e Obtenção da Saída: Com a sessão TensorFlow ativa, foram fornecidos os dados de entrada (convertidos para arrays NumPy) ao modelo e executado o método get_pooled_output(). Este método retorna a saída da última camada do modelo BERT, que é um vetor de características condensadas (ou embeddings) para a entrada fornecida.\n",
    "\n",
    ">>>>\n",
    "Saída do Modelo BERT: O resultado impresso, que parece ser um array de números reais, é a representação vetorial da entrada fornecida no espaço de características do modelo BERT. Cada número neste vetor é um componente da representação e é usado para tarefas de processamento de linguagem natural, como classificação de texto, análise de sentimento, reconhecimento de entidades nomeadas, etc.\n",
    "\n",
    "Essencialmente, a saída é a transformação de um texto de entrada em um vetor denso de recursos que encapsula informações semânticas e contextuais aprendidas pelo modelo BERT durante seu treinamento. Este vetor pode então ser utilizado em várias tarefas de NLP para realizar inferências baseadas no conteúdo e no contexto do texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc68104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert/encoder/layer_0/output/dense/kernel\n",
      "bert/encoder/layer_0/intermediate/dense/kernel\n",
      "bert/embeddings/LayerNorm/beta\n",
      "bert/encoder/layer_9/attention/self/key/bias\n",
      "bert/encoder/layer_18/attention/self/value/bias\n",
      "bert/encoder/layer_11/attention/output/dense/kernel\n",
      "bert/encoder/layer_16/attention/self/key/kernel\n",
      "bert/embeddings/LayerNorm/gamma\n",
      "bert/embeddings/position_embeddings\n",
      "bert/encoder/layer_5/intermediate/dense/bias\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_11/attention/self/query/bias\n",
      "bert/encoder/layer_23/intermediate/dense/bias\n",
      "bert/encoder/layer_1/attention/self/key/kernel\n",
      "bert/encoder/layer_5/output/dense/bias\n",
      "bert/embeddings/token_type_embeddings\n",
      "bert/encoder/layer_10/intermediate/dense/kernel\n",
      "bert/embeddings/word_embeddings\n",
      "bert/encoder/layer_17/attention/self/value/bias\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_0/attention/output/dense/bias\n",
      "bert/encoder/layer_13/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_0/attention/output/dense/kernel\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_0/attention/self/key/bias\n",
      "bert/encoder/layer_0/attention/self/key/kernel\n",
      "bert/encoder/layer_3/attention/self/key/kernel\n",
      "bert/encoder/layer_0/attention/self/query/kernel\n",
      "bert/encoder/layer_3/attention/self/key/bias\n",
      "bert/encoder/layer_23/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_0/attention/self/query/bias\n",
      "bert/encoder/layer_11/attention/self/key/kernel\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_17/output/LayerNorm/gamma\n",
      "bert/encoder/layer_11/attention/self/key/bias\n",
      "bert/encoder/layer_0/attention/self/value/kernel\n",
      "bert/encoder/layer_0/attention/self/value/bias\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_0/output/dense/bias\n",
      "bert/encoder/layer_0/intermediate/dense/bias\n",
      "bert/encoder/layer_0/output/LayerNorm/beta\n",
      "bert/encoder/layer_23/attention/self/query/kernel\n",
      "bert/encoder/layer_0/output/LayerNorm/gamma\n",
      "bert/encoder/layer_7/output/dense/kernel\n",
      "bert/encoder/layer_10/intermediate/dense/bias\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_20/attention/self/value/kernel\n",
      "bert/encoder/layer_14/attention/self/query/kernel\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_11/intermediate/dense/kernel\n",
      "bert/encoder/layer_11/intermediate/dense/bias\n",
      "bert/encoder/layer_1/attention/output/dense/bias\n",
      "bert/encoder/layer_1/attention/output/dense/kernel\n",
      "bert/encoder/layer_1/attention/self/key/bias\n",
      "bert/encoder/layer_1/attention/self/query/kernel\n",
      "bert/encoder/layer_1/attention/self/query/bias\n",
      "bert/encoder/layer_1/attention/self/value/bias\n",
      "bert/encoder/layer_1/attention/self/value/kernel\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_19/attention/output/dense/kernel\n",
      "bert/encoder/layer_1/intermediate/dense/bias\n",
      "bert/encoder/layer_1/intermediate/dense/kernel\n",
      "bert/encoder/layer_11/attention/output/dense/bias\n",
      "bert/encoder/layer_17/attention/self/key/kernel\n",
      "bert/encoder/layer_10/attention/self/query/kernel\n",
      "bert/encoder/layer_1/output/LayerNorm/beta\n",
      "bert/encoder/layer_1/output/LayerNorm/gamma\n",
      "bert/encoder/layer_1/output/dense/bias\n",
      "bert/encoder/layer_1/output/dense/kernel\n",
      "bert/encoder/layer_14/attention/self/value/bias\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_16/attention/self/query/kernel\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_10/attention/output/dense/bias\n",
      "bert/encoder/layer_10/attention/output/dense/kernel\n",
      "bert/encoder/layer_16/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_10/attention/self/key/kernel\n",
      "bert/encoder/layer_10/output/LayerNorm/gamma\n",
      "bert/encoder/layer_10/attention/self/key/bias\n",
      "bert/encoder/layer_17/attention/self/key/bias\n",
      "bert/encoder/layer_10/attention/self/query/bias\n",
      "bert/encoder/layer_22/output/LayerNorm/beta\n",
      "bert/encoder/layer_10/attention/self/value/bias\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_2/attention/output/dense/bias\n",
      "bert/encoder/layer_10/attention/self/value/kernel\n",
      "bert/encoder/layer_15/attention/self/key/bias\n",
      "bert/encoder/layer_10/output/LayerNorm/beta\n",
      "bert/encoder/layer_23/attention/self/value/kernel\n",
      "bert/encoder/layer_23/attention/self/value/bias\n",
      "bert/encoder/layer_2/output/LayerNorm/beta\n",
      "bert/encoder/layer_10/output/dense/bias\n",
      "bert/encoder/layer_10/output/dense/kernel\n",
      "bert/encoder/layer_5/intermediate/dense/kernel\n",
      "bert/encoder/layer_11/attention/self/query/kernel\n",
      "bert/encoder/layer_11/attention/self/value/bias\n",
      "bert/encoder/layer_11/attention/self/value/kernel\n",
      "bert/encoder/layer_11/output/LayerNorm/beta\n",
      "bert/encoder/layer_11/output/LayerNorm/gamma\n",
      "bert/encoder/layer_18/output/LayerNorm/beta\n",
      "bert/encoder/layer_11/output/dense/bias\n",
      "bert/encoder/layer_11/output/dense/kernel\n",
      "bert/encoder/layer_22/attention/self/query/bias\n",
      "bert/encoder/layer_12/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_12/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_12/attention/output/dense/bias\n",
      "bert/encoder/layer_21/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_2/intermediate/dense/bias\n",
      "bert/encoder/layer_12/attention/output/dense/kernel\n",
      "bert/encoder/layer_4/output/LayerNorm/beta\n",
      "bert/encoder/layer_12/attention/self/key/bias\n",
      "bert/encoder/layer_23/attention/self/key/bias\n",
      "bert/encoder/layer_18/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_12/attention/self/key/kernel\n",
      "bert/encoder/layer_12/attention/self/query/bias\n",
      "bert/encoder/layer_12/attention/self/query/kernel\n",
      "bert/encoder/layer_22/attention/output/dense/bias\n",
      "bert/encoder/layer_12/attention/self/value/bias\n",
      "bert/encoder/layer_22/attention/output/dense/kernel\n",
      "bert/encoder/layer_12/attention/self/value/kernel\n",
      "bert/encoder/layer_12/intermediate/dense/bias\n",
      "bert/encoder/layer_12/intermediate/dense/kernel\n",
      "bert/encoder/layer_8/attention/self/key/bias\n",
      "bert/encoder/layer_22/attention/self/key/kernel\n",
      "bert/encoder/layer_18/attention/output/dense/kernel\n",
      "bert/encoder/layer_12/output/LayerNorm/beta\n",
      "bert/encoder/layer_19/attention/self/query/kernel\n",
      "bert/encoder/layer_12/output/LayerNorm/gamma\n",
      "bert/encoder/layer_12/output/dense/bias\n",
      "bert/encoder/layer_12/output/dense/kernel\n",
      "bert/encoder/layer_5/attention/output/dense/kernel\n",
      "bert/encoder/layer_13/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_13/attention/output/dense/kernel\n",
      "bert/encoder/layer_13/attention/output/dense/bias\n",
      "bert/encoder/layer_13/attention/self/key/bias\n",
      "bert/encoder/layer_13/attention/self/key/kernel\n",
      "bert/encoder/layer_13/attention/self/query/bias\n",
      "bert/encoder/layer_13/attention/self/query/kernel\n",
      "bert/encoder/layer_13/attention/self/value/bias\n",
      "bert/encoder/layer_13/attention/self/value/kernel\n",
      "bert/encoder/layer_13/intermediate/dense/bias\n",
      "bert/encoder/layer_9/output/LayerNorm/beta\n",
      "bert/encoder/layer_13/intermediate/dense/kernel\n",
      "bert/encoder/layer_13/output/LayerNorm/beta\n",
      "bert/encoder/layer_2/output/dense/bias\n",
      "bert/encoder/layer_13/output/LayerNorm/gamma\n",
      "bert/encoder/layer_13/output/dense/bias\n",
      "bert/encoder/layer_13/output/dense/kernel\n",
      "bert/encoder/layer_14/attention/self/value/kernel\n",
      "bert/encoder/layer_14/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_14/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_14/attention/output/dense/bias\n",
      "bert/encoder/layer_20/output/LayerNorm/gamma\n",
      "bert/encoder/layer_14/attention/output/dense/kernel\n",
      "bert/encoder/layer_14/attention/self/key/bias\n",
      "bert/encoder/layer_7/output/LayerNorm/gamma\n",
      "bert/encoder/layer_15/output/LayerNorm/beta\n",
      "bert/encoder/layer_14/attention/self/key/kernel\n",
      "bert/encoder/layer_20/attention/self/value/bias\n",
      "bert/encoder/layer_14/attention/self/query/bias\n",
      "bert/encoder/layer_14/intermediate/dense/bias\n",
      "bert/encoder/layer_14/intermediate/dense/kernel\n",
      "bert/encoder/layer_14/output/LayerNorm/beta\n",
      "bert/encoder/layer_7/attention/self/key/kernel\n",
      "bert/encoder/layer_14/output/LayerNorm/gamma\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_14/output/dense/bias\n",
      "bert/encoder/layer_14/output/dense/kernel\n",
      "bert/encoder/layer_15/attention/self/value/bias\n",
      "bert/encoder/layer_15/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_15/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_15/attention/output/dense/bias\n",
      "bert/encoder/layer_15/attention/output/dense/kernel\n",
      "bert/encoder/layer_15/attention/self/key/kernel\n",
      "bert/encoder/layer_6/attention/output/dense/bias\n",
      "bert/encoder/layer_15/attention/self/query/bias\n",
      "bert/encoder/layer_6/attention/output/dense/kernel\n",
      "bert/encoder/layer_15/attention/self/query/kernel\n",
      "bert/encoder/layer_8/output/dense/bias\n",
      "bert/encoder/layer_15/attention/self/value/kernel\n",
      "bert/encoder/layer_15/intermediate/dense/bias\n",
      "bert/encoder/layer_15/intermediate/dense/kernel\n",
      "bert/encoder/layer_15/output/LayerNorm/gamma\n",
      "bert/encoder/layer_15/output/dense/bias\n",
      "bert/encoder/layer_15/output/dense/kernel\n",
      "bert/encoder/layer_16/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_16/attention/output/dense/bias\n",
      "bert/encoder/layer_16/attention/output/dense/kernel\n",
      "bert/encoder/layer_16/attention/self/key/bias\n",
      "bert/encoder/layer_16/attention/self/query/bias\n",
      "bert/encoder/layer_16/attention/self/value/bias\n",
      "bert/encoder/layer_16/attention/self/value/kernel\n",
      "bert/encoder/layer_16/intermediate/dense/bias\n",
      "bert/encoder/layer_16/intermediate/dense/kernel\n",
      "bert/encoder/layer_16/output/LayerNorm/beta\n",
      "bert/encoder/layer_16/output/LayerNorm/gamma\n",
      "bert/encoder/layer_8/output/LayerNorm/beta\n",
      "bert/encoder/layer_16/output/dense/bias\n",
      "bert/encoder/layer_16/output/dense/kernel\n",
      "bert/encoder/layer_17/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_17/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_17/attention/output/dense/bias\n",
      "bert/encoder/layer_17/attention/output/dense/kernel\n",
      "bert/encoder/layer_17/attention/self/query/bias\n",
      "bert/encoder/layer_17/attention/self/query/kernel\n",
      "bert/encoder/layer_17/attention/self/value/kernel\n",
      "bert/encoder/layer_17/intermediate/dense/bias\n",
      "bert/encoder/layer_17/intermediate/dense/kernel\n",
      "bert/encoder/layer_17/output/LayerNorm/beta\n",
      "bert/encoder/layer_3/attention/self/query/kernel\n",
      "bert/encoder/layer_17/output/dense/bias\n",
      "bert/encoder/layer_17/output/dense/kernel\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_19/output/dense/bias\n",
      "bert/encoder/layer_18/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_22/attention/self/key/bias\n",
      "bert/encoder/layer_18/attention/output/dense/bias\n",
      "bert/encoder/layer_18/attention/self/key/kernel\n",
      "bert/encoder/layer_18/attention/self/key/bias\n",
      "bert/encoder/layer_18/attention/self/query/bias\n",
      "bert/encoder/layer_18/attention/self/query/kernel\n",
      "bert/encoder/layer_9/attention/self/key/kernel\n",
      "bert/encoder/layer_18/attention/self/value/kernel\n",
      "bert/encoder/layer_18/intermediate/dense/bias\n",
      "bert/encoder/layer_18/intermediate/dense/kernel\n",
      "bert/encoder/layer_18/output/LayerNorm/gamma\n",
      "bert/encoder/layer_18/output/dense/bias\n",
      "bert/encoder/layer_18/output/dense/kernel\n",
      "bert/encoder/layer_4/intermediate/dense/kernel\n",
      "bert/encoder/layer_19/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_19/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_19/attention/output/dense/bias\n",
      "bert/encoder/layer_19/intermediate/dense/bias\n",
      "bert/encoder/layer_19/attention/self/key/bias\n",
      "bert/encoder/layer_19/intermediate/dense/kernel\n",
      "bert/encoder/layer_19/attention/self/key/kernel\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_19/attention/self/query/bias\n",
      "bert/encoder/layer_3/attention/output/dense/bias\n",
      "bert/encoder/layer_19/attention/self/value/bias\n",
      "bert/encoder/layer_3/attention/output/dense/kernel\n",
      "bert/encoder/layer_19/attention/self/value/kernel\n",
      "bert/encoder/layer_19/output/LayerNorm/beta\n",
      "bert/encoder/layer_20/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_19/output/LayerNorm/gamma\n",
      "bert/encoder/layer_19/output/dense/kernel\n",
      "bert/encoder/layer_7/attention/output/dense/kernel\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_2/attention/output/dense/kernel\n",
      "bert/encoder/layer_2/attention/self/key/bias\n",
      "bert/encoder/layer_2/attention/self/key/kernel\n",
      "bert/encoder/layer_2/attention/self/query/bias\n",
      "bert/encoder/layer_9/output/LayerNorm/gamma\n",
      "bert/encoder/layer_2/attention/self/query/kernel\n",
      "bert/encoder/layer_2/attention/self/value/bias\n",
      "bert/encoder/layer_2/attention/self/value/kernel\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_2/intermediate/dense/kernel\n",
      "bert/encoder/layer_2/output/LayerNorm/gamma\n",
      "bert/encoder/layer_23/attention/output/dense/bias\n",
      "bert/encoder/layer_2/output/dense/kernel\n",
      "bert/encoder/layer_20/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_20/attention/output/dense/bias\n",
      "bert/encoder/layer_20/attention/output/dense/kernel\n",
      "bert/encoder/layer_20/attention/self/key/bias\n",
      "bert/encoder/layer_6/attention/self/key/bias\n",
      "bert/encoder/layer_20/attention/self/key/kernel\n",
      "bert/encoder/layer_20/attention/self/query/bias\n",
      "bert/encoder/layer_20/attention/self/query/kernel\n",
      "bert/encoder/layer_3/output/LayerNorm/beta\n",
      "bert/encoder/layer_20/intermediate/dense/bias\n",
      "bert/encoder/layer_6/intermediate/dense/bias\n",
      "bert/encoder/layer_20/intermediate/dense/kernel\n",
      "bert/encoder/layer_20/output/LayerNorm/beta\n",
      "bert/pooler/dense/kernel\n",
      "bert/encoder/layer_20/output/dense/bias\n",
      "bert/encoder/layer_20/output/dense/kernel\n",
      "bert/encoder/layer_3/attention/self/value/bias\n",
      "bert/encoder/layer_21/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_21/attention/output/dense/bias\n",
      "bert/encoder/layer_21/attention/output/dense/kernel\n",
      "bert/encoder/layer_21/attention/self/key/bias\n",
      "bert/encoder/layer_21/attention/self/key/kernel\n",
      "bert/encoder/layer_21/attention/self/query/bias\n",
      "bert/encoder/layer_21/attention/self/query/kernel\n",
      "bert/encoder/layer_21/attention/self/value/bias\n",
      "bert/encoder/layer_9/output/dense/bias\n",
      "bert/encoder/layer_21/attention/self/value/kernel\n",
      "bert/encoder/layer_21/intermediate/dense/bias\n",
      "bert/encoder/layer_21/intermediate/dense/kernel\n",
      "bert/encoder/layer_21/output/LayerNorm/beta\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_21/output/LayerNorm/gamma\n",
      "bert/encoder/layer_21/output/dense/bias\n",
      "bert/encoder/layer_21/output/dense/kernel\n",
      "bert/encoder/layer_22/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_22/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_22/attention/self/query/kernel\n",
      "bert/encoder/layer_22/attention/self/value/bias\n",
      "bert/encoder/layer_5/attention/output/dense/bias\n",
      "bert/encoder/layer_22/attention/self/value/kernel\n",
      "bert/encoder/layer_22/intermediate/dense/bias\n",
      "bert/encoder/layer_22/intermediate/dense/kernel\n",
      "bert/encoder/layer_22/output/LayerNorm/gamma\n",
      "bert/encoder/layer_23/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_22/output/dense/bias\n",
      "bert/encoder/layer_23/output/LayerNorm/beta\n",
      "bert/encoder/layer_22/output/dense/kernel\n",
      "bert/encoder/layer_23/attention/output/dense/kernel\n",
      "bert/encoder/layer_23/attention/self/key/kernel\n",
      "bert/encoder/layer_23/attention/self/query/bias\n",
      "bert/encoder/layer_23/intermediate/dense/kernel\n",
      "bert/encoder/layer_23/output/LayerNorm/gamma\n",
      "bert/encoder/layer_23/output/dense/bias\n",
      "bert/encoder/layer_23/output/dense/kernel\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_3/attention/self/query/bias\n",
      "bert/encoder/layer_3/attention/self/value/kernel\n",
      "bert/encoder/layer_3/intermediate/dense/bias\n",
      "bert/encoder/layer_3/intermediate/dense/kernel\n",
      "bert/encoder/layer_3/output/LayerNorm/gamma\n",
      "bert/encoder/layer_3/output/dense/bias\n",
      "bert/encoder/layer_3/output/dense/kernel\n",
      "bert/encoder/layer_4/attention/output/dense/bias\n",
      "bert/encoder/layer_4/attention/output/dense/kernel\n",
      "bert/encoder/layer_4/attention/self/key/bias\n",
      "bert/encoder/layer_4/attention/self/key/kernel\n",
      "bert/encoder/layer_9/attention/self/value/bias\n",
      "bert/encoder/layer_4/attention/self/query/bias\n",
      "bert/encoder/layer_9/attention/self/value/kernel\n",
      "bert/encoder/layer_4/attention/self/query/kernel\n",
      "bert/encoder/layer_4/attention/self/value/bias\n",
      "bert/encoder/layer_4/attention/self/value/kernel\n",
      "bert/encoder/layer_4/intermediate/dense/bias\n",
      "bert/encoder/layer_4/output/LayerNorm/gamma\n",
      "bert/encoder/layer_4/output/dense/bias\n",
      "bert/encoder/layer_5/output/LayerNorm/beta\n",
      "bert/encoder/layer_4/output/dense/kernel\n",
      "bert/encoder/layer_8/attention/output/dense/bias\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_5/attention/self/key/bias\n",
      "bert/encoder/layer_5/attention/self/key/kernel\n",
      "bert/encoder/layer_5/attention/self/query/bias\n",
      "bert/encoder/layer_5/attention/self/query/kernel\n",
      "bert/encoder/layer_5/attention/self/value/kernel\n",
      "bert/encoder/layer_5/attention/self/value/bias\n",
      "bert/encoder/layer_5/output/LayerNorm/gamma\n",
      "bert/encoder/layer_5/output/dense/kernel\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_6/attention/self/key/kernel\n",
      "bert/encoder/layer_6/attention/self/query/bias\n",
      "bert/encoder/layer_6/attention/self/query/kernel\n",
      "bert/encoder/layer_6/attention/self/value/bias\n",
      "bert/encoder/layer_6/attention/self/value/kernel\n",
      "bert/encoder/layer_6/intermediate/dense/kernel\n",
      "bert/encoder/layer_6/output/LayerNorm/beta\n",
      "bert/encoder/layer_6/output/LayerNorm/gamma\n",
      "bert/encoder/layer_6/output/dense/bias\n",
      "bert/encoder/layer_6/output/dense/kernel\n",
      "bert/encoder/layer_7/attention/output/dense/bias\n",
      "bert/encoder/layer_7/attention/self/key/bias\n",
      "bert/encoder/layer_7/attention/self/query/bias\n",
      "bert/encoder/layer_7/attention/self/query/kernel\n",
      "bert/encoder/layer_7/attention/self/value/bias\n",
      "bert/encoder/layer_7/attention/self/value/kernel\n",
      "bert/encoder/layer_7/intermediate/dense/bias\n",
      "bert/encoder/layer_7/intermediate/dense/kernel\n",
      "bert/encoder/layer_7/output/LayerNorm/beta\n",
      "bert/encoder/layer_7/output/dense/bias\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_8/attention/output/dense/kernel\n",
      "bert/encoder/layer_8/attention/self/key/kernel\n",
      "bert/encoder/layer_8/attention/self/query/kernel\n",
      "bert/encoder/layer_8/attention/self/query/bias\n",
      "bert/encoder/layer_8/attention/self/value/bias\n",
      "bert/encoder/layer_8/attention/self/value/kernel\n",
      "bert/encoder/layer_8/intermediate/dense/bias\n",
      "bert/encoder/layer_8/intermediate/dense/kernel\n",
      "bert/encoder/layer_8/output/LayerNorm/gamma\n",
      "bert/encoder/layer_8/output/dense/kernel\n",
      "bert/encoder/layer_9/attention/output/dense/bias\n",
      "bert/encoder/layer_9/attention/output/dense/kernel\n",
      "bert/encoder/layer_9/attention/self/query/bias\n",
      "bert/encoder/layer_9/attention/self/query/kernel\n",
      "bert/encoder/layer_9/intermediate/dense/bias\n",
      "bert/encoder/layer_9/intermediate/dense/kernel\n",
      "bert/encoder/layer_9/output/dense/kernel\n",
      "bert/pooler/dense/bias\n"
     ]
    }
   ],
   "source": [
    "# Modelo Bert\n",
    "\n",
    "def list_variables_in_checkpoint(checkpoint_path):\n",
    "    try:\n",
    "        # Carregar o checkpoint\n",
    "        reader = tf.train.load_checkpoint(checkpoint_path)\n",
    "        \n",
    "        # Listar todas as chaves (nomes dos tensors)\n",
    "        return reader.get_variable_to_dtype_map().keys()\n",
    "    except Exception as e:  \n",
    "        print(\"Erro ao carregar o checkpoint:\", e)\n",
    "        return []\n",
    "\n",
    "\n",
    "checkpoint_path = 'BertLarge_tf1_v4'\n",
    "variables = list_variables_in_checkpoint(checkpoint_path)\n",
    "for var in variables:\n",
    "    print(var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "794e353e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert/encoder/layer_0/output/dense/kernel\n",
      "bert/encoder/layer_0/intermediate/dense/kernel\n",
      "bert/embeddings/LayerNorm/beta\n",
      "bert/encoder/layer_9/attention/self/key/bias\n",
      "bert/encoder/layer_18/attention/self/value/bias\n",
      "bert/encoder/layer_11/attention/output/dense/kernel\n",
      "bert/encoder/layer_16/attention/self/key/kernel\n",
      "bert/embeddings/LayerNorm/gamma\n",
      "bert/embeddings/position_embeddings\n",
      "bert/encoder/layer_5/intermediate/dense/bias\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_11/attention/self/query/bias\n",
      "bert/encoder/layer_23/intermediate/dense/bias\n",
      "bert/encoder/layer_1/attention/self/key/kernel\n",
      "bert/encoder/layer_5/output/dense/bias\n",
      "bert/embeddings/token_type_embeddings\n",
      "bert/encoder/layer_10/intermediate/dense/kernel\n",
      "bert/embeddings/word_embeddings\n",
      "bert/encoder/layer_17/attention/self/value/bias\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_0/attention/output/dense/bias\n",
      "bert/encoder/layer_13/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_0/attention/output/dense/kernel\n",
      "bert/encoder/layer_0/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_0/attention/self/key/bias\n",
      "bert/encoder/layer_0/attention/self/key/kernel\n",
      "bert/encoder/layer_3/attention/self/key/kernel\n",
      "bert/encoder/layer_0/attention/self/query/kernel\n",
      "bert/encoder/layer_3/attention/self/key/bias\n",
      "bert/encoder/layer_23/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_0/attention/self/query/bias\n",
      "bert/encoder/layer_11/attention/self/key/kernel\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_17/output/LayerNorm/gamma\n",
      "bert/encoder/layer_11/attention/self/key/bias\n",
      "bert/encoder/layer_0/attention/self/value/kernel\n",
      "bert/encoder/layer_0/attention/self/value/bias\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_0/output/dense/bias\n",
      "bert/encoder/layer_0/intermediate/dense/bias\n",
      "bert/encoder/layer_0/output/LayerNorm/beta\n",
      "bert/encoder/layer_23/attention/self/query/kernel\n",
      "bert/encoder/layer_0/output/LayerNorm/gamma\n",
      "bert/encoder/layer_7/output/dense/kernel\n",
      "bert/encoder/layer_10/intermediate/dense/bias\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_20/attention/self/value/kernel\n",
      "bert/encoder/layer_14/attention/self/query/kernel\n",
      "bert/encoder/layer_1/attention/output/LayerNorm/gamma\n",
      "cls/predictions/output_bias\n",
      "bert/encoder/layer_11/intermediate/dense/kernel\n",
      "bert/encoder/layer_11/intermediate/dense/bias\n",
      "bert/encoder/layer_1/attention/output/dense/bias\n",
      "bert/encoder/layer_1/attention/output/dense/kernel\n",
      "bert/encoder/layer_1/attention/self/key/bias\n",
      "bert/encoder/layer_1/attention/self/query/kernel\n",
      "bert/encoder/layer_1/attention/self/query/bias\n",
      "bert/encoder/layer_1/attention/self/value/bias\n",
      "bert/encoder/layer_1/attention/self/value/kernel\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_19/attention/output/dense/kernel\n",
      "bert/encoder/layer_1/intermediate/dense/bias\n",
      "bert/encoder/layer_1/intermediate/dense/kernel\n",
      "bert/encoder/layer_11/attention/output/dense/bias\n",
      "bert/encoder/layer_17/attention/self/key/kernel\n",
      "bert/encoder/layer_10/attention/self/query/kernel\n",
      "bert/encoder/layer_1/output/LayerNorm/beta\n",
      "bert/encoder/layer_1/output/LayerNorm/gamma\n",
      "bert/encoder/layer_1/output/dense/bias\n",
      "bert/encoder/layer_1/output/dense/kernel\n",
      "bert/encoder/layer_14/attention/self/value/bias\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_16/attention/self/query/kernel\n",
      "bert/encoder/layer_10/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_10/attention/output/dense/bias\n",
      "bert/encoder/layer_10/attention/output/dense/kernel\n",
      "bert/encoder/layer_16/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_10/attention/self/key/kernel\n",
      "bert/encoder/layer_10/output/LayerNorm/gamma\n",
      "bert/encoder/layer_10/attention/self/key/bias\n",
      "bert/encoder/layer_17/attention/self/key/bias\n",
      "bert/encoder/layer_10/attention/self/query/bias\n",
      "bert/encoder/layer_22/output/LayerNorm/beta\n",
      "bert/encoder/layer_10/attention/self/value/bias\n",
      "bert/encoder/layer_11/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_2/attention/output/dense/bias\n",
      "bert/encoder/layer_10/attention/self/value/kernel\n",
      "bert/encoder/layer_15/attention/self/key/bias\n",
      "bert/encoder/layer_10/output/LayerNorm/beta\n",
      "bert/encoder/layer_23/attention/self/value/kernel\n",
      "bert/encoder/layer_23/attention/self/value/bias\n",
      "bert/encoder/layer_2/output/LayerNorm/beta\n",
      "bert/encoder/layer_10/output/dense/bias\n",
      "bert/encoder/layer_10/output/dense/kernel\n",
      "bert/encoder/layer_5/intermediate/dense/kernel\n",
      "bert/encoder/layer_11/attention/self/query/kernel\n",
      "bert/encoder/layer_11/attention/self/value/bias\n",
      "bert/encoder/layer_11/attention/self/value/kernel\n",
      "bert/encoder/layer_11/output/LayerNorm/beta\n",
      "bert/encoder/layer_11/output/LayerNorm/gamma\n",
      "bert/encoder/layer_18/output/LayerNorm/beta\n",
      "bert/encoder/layer_11/output/dense/bias\n",
      "bert/encoder/layer_11/output/dense/kernel\n",
      "bert/encoder/layer_22/attention/self/query/bias\n",
      "bert/encoder/layer_12/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_12/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_12/attention/output/dense/bias\n",
      "bert/encoder/layer_21/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_2/intermediate/dense/bias\n",
      "bert/encoder/layer_12/attention/output/dense/kernel\n",
      "bert/encoder/layer_4/output/LayerNorm/beta\n",
      "bert/encoder/layer_12/attention/self/key/bias\n",
      "bert/encoder/layer_23/attention/self/key/bias\n",
      "bert/encoder/layer_18/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_12/attention/self/key/kernel\n",
      "bert/encoder/layer_12/attention/self/query/bias\n",
      "bert/encoder/layer_12/attention/self/query/kernel\n",
      "bert/encoder/layer_22/attention/output/dense/bias\n",
      "bert/encoder/layer_12/attention/self/value/bias\n",
      "bert/encoder/layer_22/attention/output/dense/kernel\n",
      "bert/encoder/layer_12/attention/self/value/kernel\n",
      "bert/encoder/layer_12/intermediate/dense/bias\n",
      "bert/encoder/layer_12/intermediate/dense/kernel\n",
      "bert/encoder/layer_8/attention/self/key/bias\n",
      "bert/encoder/layer_22/attention/self/key/kernel\n",
      "bert/encoder/layer_18/attention/output/dense/kernel\n",
      "bert/encoder/layer_12/output/LayerNorm/beta\n",
      "bert/encoder/layer_19/attention/self/query/kernel\n",
      "bert/encoder/layer_12/output/LayerNorm/gamma\n",
      "bert/encoder/layer_12/output/dense/bias\n",
      "bert/encoder/layer_12/output/dense/kernel\n",
      "bert/encoder/layer_5/attention/output/dense/kernel\n",
      "bert/encoder/layer_13/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_13/attention/output/dense/kernel\n",
      "bert/encoder/layer_13/attention/output/dense/bias\n",
      "bert/encoder/layer_13/attention/self/key/bias\n",
      "bert/encoder/layer_13/attention/self/key/kernel\n",
      "bert/encoder/layer_13/attention/self/query/bias\n",
      "bert/encoder/layer_13/attention/self/query/kernel\n",
      "bert/encoder/layer_13/attention/self/value/bias\n",
      "bert/encoder/layer_13/attention/self/value/kernel\n",
      "bert/encoder/layer_13/intermediate/dense/bias\n",
      "bert/encoder/layer_9/output/LayerNorm/beta\n",
      "bert/encoder/layer_13/intermediate/dense/kernel\n",
      "bert/encoder/layer_13/output/LayerNorm/beta\n",
      "bert/encoder/layer_2/output/dense/bias\n",
      "bert/encoder/layer_13/output/LayerNorm/gamma\n",
      "bert/encoder/layer_13/output/dense/bias\n",
      "bert/encoder/layer_13/output/dense/kernel\n",
      "bert/encoder/layer_14/attention/self/value/kernel\n",
      "bert/encoder/layer_14/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_14/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_14/attention/output/dense/bias\n",
      "bert/encoder/layer_20/output/LayerNorm/gamma\n",
      "bert/encoder/layer_14/attention/output/dense/kernel\n",
      "bert/encoder/layer_14/attention/self/key/bias\n",
      "bert/encoder/layer_7/output/LayerNorm/gamma\n",
      "bert/encoder/layer_15/output/LayerNorm/beta\n",
      "bert/encoder/layer_14/attention/self/key/kernel\n",
      "bert/encoder/layer_20/attention/self/value/bias\n",
      "bert/encoder/layer_14/attention/self/query/bias\n",
      "bert/encoder/layer_14/intermediate/dense/bias\n",
      "bert/encoder/layer_14/intermediate/dense/kernel\n",
      "bert/encoder/layer_14/output/LayerNorm/beta\n",
      "bert/encoder/layer_7/attention/self/key/kernel\n",
      "bert/encoder/layer_14/output/LayerNorm/gamma\n",
      "bert/encoder/layer_4/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_14/output/dense/bias\n",
      "bert/encoder/layer_14/output/dense/kernel\n",
      "bert/encoder/layer_15/attention/self/value/bias\n",
      "bert/encoder/layer_15/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_15/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_15/attention/output/dense/bias\n",
      "bert/encoder/layer_15/attention/output/dense/kernel\n",
      "bert/encoder/layer_15/attention/self/key/kernel\n",
      "bert/encoder/layer_6/attention/output/dense/bias\n",
      "bert/encoder/layer_15/attention/self/query/bias\n",
      "bert/encoder/layer_6/attention/output/dense/kernel\n",
      "bert/encoder/layer_15/attention/self/query/kernel\n",
      "bert/encoder/layer_8/output/dense/bias\n",
      "bert/encoder/layer_15/attention/self/value/kernel\n",
      "bert/encoder/layer_15/intermediate/dense/bias\n",
      "bert/encoder/layer_15/intermediate/dense/kernel\n",
      "bert/encoder/layer_15/output/LayerNorm/gamma\n",
      "bert/encoder/layer_15/output/dense/bias\n",
      "bert/encoder/layer_15/output/dense/kernel\n",
      "bert/encoder/layer_16/attention/output/LayerNorm/gamma\n",
      "cls/seq_relationship/output_bias\n",
      "bert/encoder/layer_16/attention/output/dense/bias\n",
      "bert/encoder/layer_16/attention/output/dense/kernel\n",
      "bert/encoder/layer_16/attention/self/key/bias\n",
      "bert/encoder/layer_16/attention/self/query/bias\n",
      "bert/encoder/layer_16/attention/self/value/bias\n",
      "bert/encoder/layer_16/attention/self/value/kernel\n",
      "bert/encoder/layer_16/intermediate/dense/bias\n",
      "bert/encoder/layer_16/intermediate/dense/kernel\n",
      "bert/encoder/layer_16/output/LayerNorm/beta\n",
      "bert/encoder/layer_16/output/LayerNorm/gamma\n",
      "bert/encoder/layer_8/output/LayerNorm/beta\n",
      "bert/encoder/layer_16/output/dense/bias\n",
      "bert/encoder/layer_16/output/dense/kernel\n",
      "bert/encoder/layer_17/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_17/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_17/attention/output/dense/bias\n",
      "bert/encoder/layer_17/attention/output/dense/kernel\n",
      "bert/encoder/layer_17/attention/self/query/bias\n",
      "bert/encoder/layer_17/attention/self/query/kernel\n",
      "bert/encoder/layer_17/attention/self/value/kernel\n",
      "bert/encoder/layer_17/intermediate/dense/bias\n",
      "cls/seq_relationship/output_weights\n",
      "bert/encoder/layer_17/intermediate/dense/kernel\n",
      "bert/encoder/layer_17/output/LayerNorm/beta\n",
      "bert/encoder/layer_3/attention/self/query/kernel\n",
      "bert/encoder/layer_17/output/dense/bias\n",
      "bert/encoder/layer_17/output/dense/kernel\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_19/output/dense/bias\n",
      "bert/encoder/layer_18/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_22/attention/self/key/bias\n",
      "bert/encoder/layer_18/attention/output/dense/bias\n",
      "bert/encoder/layer_18/attention/self/key/kernel\n",
      "bert/encoder/layer_18/attention/self/key/bias\n",
      "bert/encoder/layer_18/attention/self/query/bias\n",
      "bert/encoder/layer_18/attention/self/query/kernel\n",
      "bert/encoder/layer_9/attention/self/key/kernel\n",
      "bert/encoder/layer_18/attention/self/value/kernel\n",
      "bert/encoder/layer_18/intermediate/dense/bias\n",
      "bert/encoder/layer_18/intermediate/dense/kernel\n",
      "bert/encoder/layer_18/output/LayerNorm/gamma\n",
      "bert/encoder/layer_18/output/dense/bias\n",
      "bert/encoder/layer_18/output/dense/kernel\n",
      "bert/encoder/layer_4/intermediate/dense/kernel\n",
      "bert/encoder/layer_19/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_19/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_19/attention/output/dense/bias\n",
      "bert/encoder/layer_19/intermediate/dense/bias\n",
      "bert/encoder/layer_19/attention/self/key/bias\n",
      "bert/encoder/layer_19/intermediate/dense/kernel\n",
      "bert/encoder/layer_19/attention/self/key/kernel\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_19/attention/self/query/bias\n",
      "bert/encoder/layer_3/attention/output/dense/bias\n",
      "bert/encoder/layer_19/attention/self/value/bias\n",
      "bert/encoder/layer_3/attention/output/dense/kernel\n",
      "bert/encoder/layer_19/attention/self/value/kernel\n",
      "bert/encoder/layer_19/output/LayerNorm/beta\n",
      "bert/encoder/layer_20/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_19/output/LayerNorm/gamma\n",
      "bert/encoder/layer_19/output/dense/kernel\n",
      "bert/encoder/layer_7/attention/output/dense/kernel\n",
      "bert/encoder/layer_2/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_2/attention/output/dense/kernel\n",
      "bert/encoder/layer_2/attention/self/key/bias\n",
      "bert/encoder/layer_2/attention/self/key/kernel\n",
      "bert/encoder/layer_2/attention/self/query/bias\n",
      "bert/encoder/layer_9/output/LayerNorm/gamma\n",
      "bert/encoder/layer_2/attention/self/query/kernel\n",
      "bert/encoder/layer_2/attention/self/value/bias\n",
      "bert/encoder/layer_2/attention/self/value/kernel\n",
      "bert/encoder/layer_7/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_2/intermediate/dense/kernel\n",
      "bert/encoder/layer_2/output/LayerNorm/gamma\n",
      "bert/encoder/layer_23/attention/output/dense/bias\n",
      "bert/encoder/layer_2/output/dense/kernel\n",
      "bert/encoder/layer_20/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_20/attention/output/dense/bias\n",
      "bert/encoder/layer_20/attention/output/dense/kernel\n",
      "bert/encoder/layer_20/attention/self/key/bias\n",
      "bert/encoder/layer_6/attention/self/key/bias\n",
      "bert/encoder/layer_20/attention/self/key/kernel\n",
      "bert/encoder/layer_20/attention/self/query/bias\n",
      "cls/predictions/transform/dense/bias\n",
      "bert/encoder/layer_20/attention/self/query/kernel\n",
      "bert/encoder/layer_3/output/LayerNorm/beta\n",
      "bert/encoder/layer_20/intermediate/dense/bias\n",
      "bert/encoder/layer_6/intermediate/dense/bias\n",
      "bert/encoder/layer_20/intermediate/dense/kernel\n",
      "bert/encoder/layer_20/output/LayerNorm/beta\n",
      "bert/pooler/dense/kernel\n",
      "bert/encoder/layer_20/output/dense/bias\n",
      "bert/encoder/layer_20/output/dense/kernel\n",
      "bert/encoder/layer_3/attention/self/value/bias\n",
      "bert/encoder/layer_21/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_21/attention/output/dense/bias\n",
      "bert/encoder/layer_21/attention/output/dense/kernel\n",
      "bert/encoder/layer_21/attention/self/key/bias\n",
      "bert/encoder/layer_21/attention/self/key/kernel\n",
      "bert/encoder/layer_21/attention/self/query/bias\n",
      "bert/encoder/layer_21/attention/self/query/kernel\n",
      "bert/encoder/layer_21/attention/self/value/bias\n",
      "bert/encoder/layer_9/output/dense/bias\n",
      "bert/encoder/layer_21/attention/self/value/kernel\n",
      "bert/encoder/layer_21/intermediate/dense/bias\n",
      "bert/encoder/layer_21/intermediate/dense/kernel\n",
      "bert/encoder/layer_21/output/LayerNorm/beta\n",
      "bert/encoder/layer_9/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_21/output/LayerNorm/gamma\n",
      "bert/encoder/layer_21/output/dense/bias\n",
      "bert/encoder/layer_21/output/dense/kernel\n",
      "bert/encoder/layer_22/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_22/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_22/attention/self/query/kernel\n",
      "bert/encoder/layer_22/attention/self/value/bias\n",
      "bert/encoder/layer_5/attention/output/dense/bias\n",
      "bert/encoder/layer_22/attention/self/value/kernel\n",
      "bert/encoder/layer_22/intermediate/dense/bias\n",
      "bert/encoder/layer_22/intermediate/dense/kernel\n",
      "bert/encoder/layer_22/output/LayerNorm/gamma\n",
      "bert/encoder/layer_23/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_22/output/dense/bias\n",
      "bert/encoder/layer_23/output/LayerNorm/beta\n",
      "bert/encoder/layer_22/output/dense/kernel\n",
      "bert/encoder/layer_23/attention/output/dense/kernel\n",
      "bert/encoder/layer_23/attention/self/key/kernel\n",
      "bert/encoder/layer_23/attention/self/query/bias\n",
      "bert/encoder/layer_23/intermediate/dense/kernel\n",
      "bert/encoder/layer_23/output/LayerNorm/gamma\n",
      "bert/encoder/layer_23/output/dense/bias\n",
      "bert/encoder/layer_23/output/dense/kernel\n",
      "bert/encoder/layer_3/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_3/attention/self/query/bias\n",
      "bert/encoder/layer_3/attention/self/value/kernel\n",
      "bert/encoder/layer_3/intermediate/dense/bias\n",
      "bert/encoder/layer_3/intermediate/dense/kernel\n",
      "bert/encoder/layer_3/output/LayerNorm/gamma\n",
      "bert/encoder/layer_3/output/dense/bias\n",
      "bert/encoder/layer_3/output/dense/kernel\n",
      "bert/encoder/layer_4/attention/output/dense/bias\n",
      "bert/encoder/layer_4/attention/output/dense/kernel\n",
      "bert/encoder/layer_4/attention/self/key/bias\n",
      "bert/encoder/layer_4/attention/self/key/kernel\n",
      "bert/encoder/layer_9/attention/self/value/bias\n",
      "bert/encoder/layer_4/attention/self/query/bias\n",
      "bert/encoder/layer_9/attention/self/value/kernel\n",
      "bert/encoder/layer_4/attention/self/query/kernel\n",
      "bert/encoder/layer_4/attention/self/value/bias\n",
      "bert/encoder/layer_4/attention/self/value/kernel\n",
      "bert/encoder/layer_4/intermediate/dense/bias\n",
      "bert/encoder/layer_4/output/LayerNorm/gamma\n",
      "bert/encoder/layer_4/output/dense/bias\n",
      "bert/encoder/layer_5/output/LayerNorm/beta\n",
      "bert/encoder/layer_4/output/dense/kernel\n",
      "bert/encoder/layer_8/attention/output/dense/bias\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_5/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_5/attention/self/key/bias\n",
      "bert/encoder/layer_5/attention/self/key/kernel\n",
      "bert/encoder/layer_5/attention/self/query/bias\n",
      "bert/encoder/layer_5/attention/self/query/kernel\n",
      "bert/encoder/layer_5/attention/self/value/kernel\n",
      "bert/encoder/layer_5/attention/self/value/bias\n",
      "bert/encoder/layer_5/output/LayerNorm/gamma\n",
      "bert/encoder/layer_5/output/dense/kernel\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/beta\n",
      "bert/encoder/layer_6/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_6/attention/self/key/kernel\n",
      "bert/encoder/layer_6/attention/self/query/bias\n",
      "bert/encoder/layer_6/attention/self/query/kernel\n",
      "bert/encoder/layer_6/attention/self/value/bias\n",
      "bert/encoder/layer_6/attention/self/value/kernel\n",
      "bert/encoder/layer_6/intermediate/dense/kernel\n",
      "bert/encoder/layer_6/output/LayerNorm/beta\n",
      "bert/encoder/layer_6/output/LayerNorm/gamma\n",
      "bert/encoder/layer_6/output/dense/bias\n",
      "bert/encoder/layer_6/output/dense/kernel\n",
      "bert/encoder/layer_7/attention/output/dense/bias\n",
      "bert/encoder/layer_7/attention/self/key/bias\n",
      "bert/encoder/layer_7/attention/self/query/bias\n",
      "bert/encoder/layer_7/attention/self/query/kernel\n",
      "bert/encoder/layer_7/attention/self/value/bias\n",
      "bert/encoder/layer_7/attention/self/value/kernel\n",
      "bert/encoder/layer_7/intermediate/dense/bias\n",
      "bert/encoder/layer_7/intermediate/dense/kernel\n",
      "bert/encoder/layer_7/output/LayerNorm/beta\n",
      "bert/encoder/layer_7/output/dense/bias\n",
      "bert/encoder/layer_8/attention/output/LayerNorm/gamma\n",
      "bert/encoder/layer_8/attention/output/dense/kernel\n",
      "bert/encoder/layer_8/attention/self/key/kernel\n",
      "bert/encoder/layer_8/attention/self/query/kernel\n",
      "bert/encoder/layer_8/attention/self/query/bias\n",
      "bert/encoder/layer_8/attention/self/value/bias\n",
      "bert/encoder/layer_8/attention/self/value/kernel\n",
      "bert/encoder/layer_8/intermediate/dense/bias\n",
      "bert/encoder/layer_8/intermediate/dense/kernel\n",
      "bert/encoder/layer_8/output/LayerNorm/gamma\n",
      "bert/encoder/layer_8/output/dense/kernel\n",
      "bert/encoder/layer_9/attention/output/dense/bias\n",
      "bert/encoder/layer_9/attention/output/dense/kernel\n",
      "bert/encoder/layer_9/attention/self/query/bias\n",
      "bert/encoder/layer_9/attention/self/query/kernel\n",
      "bert/encoder/layer_9/intermediate/dense/bias\n",
      "bert/encoder/layer_9/intermediate/dense/kernel\n",
      "bert/encoder/layer_9/output/dense/kernel\n",
      "bert/pooler/dense/bias\n",
      "cls/predictions/transform/LayerNorm/beta\n",
      "cls/predictions/transform/LayerNorm/gamma\n",
      "cls/predictions/transform/dense/kernel\n"
     ]
    }
   ],
   "source": [
    "# Modelo original bert_cased_L-24_H-1024_A-16 (pré-BERTimbau)\n",
    "\n",
    "def list_variables_in_checkpoint(checkpoint_path):\n",
    "    try:\n",
    "        # Carregar o checkpoint\n",
    "        reader = tf.train.load_checkpoint(checkpoint_path)\n",
    "        \n",
    "        # Listar todas as chaves (nomes dos tensors)\n",
    "        return reader.get_variable_to_dtype_map().keys()\n",
    "    except Exception as e:  \n",
    "        print(\"Erro ao carregar o checkpoint:\", e)\n",
    "        return []\n",
    "\n",
    "\n",
    "checkpoint_path = 'bert_cased_L-24_H-1024_A-16/bert_model.ckpt'\n",
    "variables = list_variables_in_checkpoint(checkpoint_path)\n",
    "for var in variables:\n",
    "    print(var)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
